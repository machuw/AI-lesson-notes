# FAQ

## 12.19
「 李昊-上海: #每日最少学习时间打卡#12.19
完成今日最少学习2小时+承诺1小时
我学到了：在 sklearn 中定义、训练模型、拆分数据集
我的问题是：面对不同的数据，逻辑回归、神经网络、决策树、SVM如何选择合适的分类算法来解决问题 」
- - - - - - - - - - - - - - -
问的非常好，这是我们经常会遇到的问题。每个算法都有自己的优缺点，在接下来的学习当中我们会详细学习你问到的每种算法。每一种算法有着自己的特点特性，简单来说每一种方法其实都能解决回归或者分类问题，我们首先会分析数据的特点，比如数据的特征不多的情况下可能会选用决策树，因为决策树对是否为线性没有要求，但逻辑回归会有要求。而对于神经网络，svm，神经网络需要多方面的调参，在数据特征很多的情况下，我们会引入深度学习，因为一层的神经网络不够用的。svm可以处理高维度的特征，用核函数来处理非线性的特征空间。可以参考一下这篇文章 https://blog.csdn.net/oliverkehl/article/details/50129999 
但是从工作中来说，我们的数据一般都是有很多特征，这种情况我们会很难通过数据可视化来区分是否线性。所以通俗点来说，我们会通过简单的观察后，每个算法都会跑一遍，看哪种效果最好。当你处理数据和调试模型到一定程度之后，你会一看数据大致知道需要什么算法来试试等等

「 郴江笑笑生: #每日最少学习时间打卡#12.19
完成今日最少学习 2小时
我学到了：总结了常用机器学习算法
打卡两个小时。今天帮人翻译了一篇目标检测，所以学习时间不多。
问题:对于GD和naive  bayes，需要更多数学层次的理解和解释。 」
- - - - - - - - - - - - - - -
哈哈做笔记很赞~关于你的问题，在我们的监督学习里可以学习到，我也会在直播课中给大家详细再过一过~这里有两个参考的链接，可以先看一看，有基础或者有兴趣的同学也可以看一下，里面会有一些公式的讲解和例子
https://www.jianshu.com/p/c7e642877b0e
http://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html

#每日最少学习时间打卡#12.19
完成今日最少学习 2小时
我学到了：机器学习算法是如何从实际的问题中产生的。
问题：简绍的算法中，大多数为分类的算法。除了线性回归，还有哪些回归问题的算法呢？
- - - - - - - - - - -
简介里面的，其实所有的算法都可以用来做回归的喔，后面的课程会有讲到的.LR一般我们会用来做baseline，用来做基准的模型.

## 12.20
「 远超-北京-互联网: #每日最少学习时间打卡#12.20
完成今日最少学习 2小时
我学到了：简单决策树的使用。
问题：实际使用中决策树模型中使用什么方法或者指标来选取特征的？ 」
- - - - - - - - - - - - - - -
决策树模型一般是使用信息熵来算信息增益，常用的信息熵有ID3.5, C4.5,还有CART，后面的课程我们会学习到信息熵和信息增益的概念但不会详细讲不同的计算方法，我会在直播课中给大家讲讲上面三种不同算法的公式及优缺点。通俗点来说，某个特征的信息熵的值越小，这个特征的信息增益就越大，也就是说我们选用这个属性来划分，就越可信。简单来讲，我们用信息增益来选取特征进行划分

## 12.21
#每日最少学习时间打卡#12.21
完成今日最少学习 2小时
我学到了：简单实用sklearn库训练模型，手动调整参数，并对数据集进行训练数据和测试数据的拆分，目的是为了实用测试数据来测试模型效果；了解了评估模型效果的指标。

## 12.22
「 远超-北京-互联网: #每日最少学习时间打卡#12.22
完成今日最少学习3小时
我学到了：1）评估指标：混淆矩阵，以及可以从混淆矩阵推导出的准确率、精度、召回率等指标，F1和F-β 得分是综合了精度和召回率的指标，ROC曲线以及AUC是根据真/假阳性率得出的指标。回归指标：平均绝对误差、均方误差、R2得分；2）模型选择：使用交叉验证等方法避免模型的欠/过拟合问题，根据学习曲线（训练误差和测试误差曲线）判断模型的拟合性能；3）网格搜索
问题：1）模型指标是不是可以认为有两类：一类为分类指标，如F1、AUC等；一类为回归指标，如R2；2）判断学习曲线的好坏只能通过肉眼判断？没有没有评价的指标？3）在网格搜索例子中，我们使用的评估指标是F1得分，我理解其他指标如AUC应该也可以使用，那指标之前是如何取舍的？ 」
- - - - - - - - - - - - - - -
1.正确，是可以这样认为的，因为分类主要是判断是与不是，无法用具体的数值来量化，而回归是会有很精细的误差，需要可以量化的指标来判断
2.判断学习曲线我们也可以用机器来判断，其实网格搜索就是其中一种不需要我们人工来判断学习曲线的方法，这个学习曲线在课程中的例子就是为了让我们直观的感受到什么是过拟合，然后如何避免，以及后面的网格搜索的方法就是我们常用的防止过拟合的方法
3.没错，我们可以用不同的指标来评估，至于指标之间如何取舍，其实就有点类似我们如何决定F-β得分中β的值，根据我们的数据的分布情况，以及我们最终想要的结果，来决定使用何种评估指标。再深入点说，我们也可以采用不同的评价指标，来分析为什么不同的评价指标会得到不同的结果，这样可以更好的帮助我们分析。
@远超-北京-互联网

## 12.25
「 远超-北京-互联网: #每日最少学习时间打卡#12.25
完成今日最少学习2小时
我学到了：1）整理复习项目一的评审和代码；2）线性回归，了解绝对值/平方技巧和梯度回归的关系，平均绝对值误差和均方误差的不同；
问题：1）线性回归的11小节01:22秒处说“可以在教学笔记里看到详细的运算”，请问这个教学笔记从哪里获取；2）线性回归这节的梯度下降讲得还是比较抽象，希望看到随机梯度下降或者批量梯度下降算法在一个简单例子中的运算步骤，以及迭代的终止条件等。下来我也会找其他资料再深入了解一下。 」
- - - - - - - - - - - - - - -
1.关于第一个问题，我已经联系了相关负责人，问一问看能不能找到
2. 关于梯度下降呢，这里有个比较深入的解释 https://www.jianshu.com/p/c7e642877b0e 
简单来讲，比如 f(X) =w1*x1 + w2*x2 + w0,那么这个函数的梯度就是(w1,w2)，也就是在x1这个feature的方向的梯度为w1，x2这个feature的方向的梯度为w2

## 12.26
「 远超-北京-互联网: #每日最少学习时间打卡#12.26
完成今日最少学习1小时
我学到了：学习梯度下降知识，了解了梯度下降的迭代公式，从单变量到多变量梯度计算方法，使用均方误差作为误差函数，手动实现了一个多变量线性回归的批量梯度下降算法 」
- - - - - - - - - - - - - - -
棒啊！！感觉可以分享你的代码出来，让大家也学习一下喔~ [奸笑]@远超-北京-互联网

## 12.27
「 冯小平 北京 软件工程师: #每日最少学习时间打卡#12.26
完成今日最少学习5小时
我学到了：线性回归（比NG的讲得容易很多），感知器（看到了久违的真值表），决策树（用GridSearch跑了三个参数偶等了20分钟还没结束...）
问题：https://shimo.im/docs/q65dKfofc0MZuEHN 」
- - - - - - - - - - - - - - -
问题问的很详细啊哈哈哈，让我逐一解答：

1. 因为实际上你是要判断x相等的情况下，实际的y值与你预测的线的值y_head之间的差值
2. 如果你不同时变化，一次迭代中，某一个参数会变化多次，求出来的参数值就没有意义了
3. N个数值的均方误差是不是等于总平方误差除以N？[奸笑]
4. 你上面print出来的是grid.best_score，你尝试用求出来的best parameters在整个训练集上训练一个模型；这个best_score是你所有cv的平均accuracy, 是在训练集的基础上分出来的train和validation.要牢记，你用grid search是求最优参数，不是直接训练了一个最优的模型，找到最优参数，用这个参数去训练整个训练集
5. make_scorer是专门用来为grid_search服务的，详情看一下这个https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html
6. load_boston是因为这个boston的数据内置在sklearn_data里了https://scikit-learn.org/stable/datasets/index.html；不需要转换成array呀，直接提取就好了，bmi_life_data[['BMI']]
7. 这个问题我不太清楚你问的是哪里，但是一般情况下num_epochs=batch_numbers，也就是说你数据集分成了多少个batchs，你就有多少个epochs
8. 一般epoch是根据你的batch_size来定，而batch_size是根据你的计算资源来定，比如你的GPU是6GB的大小，可能batch_size=16，那epoch_num就会大，因为batch比较多，而你有12GB的显存计算，就可以加大batch_size,epoch减少；learning_rate根据你的收敛速度和来调整，后面深度学习应该会再深入讲解的~

「 Sherry 上海 精算咨询: 我还有问题是：（包括之前问过大助教的）构建垃圾邮件分类项目里，naive_bayes.predict(testing_data)最终能得出一堆0和1的array，但视频里主要讲的理论都是算一个probability，想问一下这个0和1的prediction具体是怎么得出的？ 」
- - - - - - - - - - - - - - -
因为在用naive_bayes来做分类，比如这个模型是用来区分这个动物是不是狗狗，是狗狗的话，为1，不是，为0.概率大于0.6（阈值）的时候，是狗，即为1，而小于0.6的话，会判断为不是狗，即为0.在Sklearn里MultinomialNB classifier就是naive_bayes的classifier,  NB=NaiveBayes.你猜的是对的@Sherry 上海 精算咨询

「 远超-北京-互联网: #每日最少学习时间打卡#12.26
完成今日最少学习2小时
我学到了：完成线性回归单元学习
问题：1）多项式回归的例子中，举的是单变量的多项式回归，那有没有多变量的多项式回归？公式如何？多项式回归中的最高项为多少怎么决定？（是使用网格搜索来找么？）
2）正则化是怎么应用到模型选择中的？是在模型拟合过程中使用，还是在模型拟合后，再计算模型的系数？另外对L1和L2正则化优点备忘单的所列的点都不是很理解，为什么正则化会和求导相关？为什么和特征选择相关？正则化这节听得还是比较模糊，有更详细的资料可以了解么？ 」
- - - - - - - - - - - - - - -
1.多项式回归多变量其实就是多元多项式回归，你问到的其实都是属于调参了，一般涉及到调参，大多数时候会使用网格搜索，但是有可能因为数据量太大，网格搜索会消耗大量的时间，而实际应用中，其实很少会使用多项式多元回归，这种情况下，拟合效果较差，而且很耗时。
2.实际上引入正则化之后就变成了另一种模型了,加入L1变成Lasso regression,加入L2变成Ridge regression, 两个都加变成Elastic Net Regression;这些都是不同的模型。因为相当于加入了正则化之后才去使用梯度下降，所以需要求导。和特征选择相关是L1可以，可以观察到我们是对特征的系数进行惩罚，所以如果系数为0的话，代表这个特征在模型中就没有了，这常应用在数据集比较稀疏的情况下。可以参考一下这篇文章：https://blog.csdn.net/jinping_shi/article/details/52433975
@远超-北京-互联网

## 12.28
「 卓之: #每日最少学习时间打卡#12.28
完成今日最少学习 4小时。
我学到了：看完了线性回归中的视频。
问题：正则化没看懂。为什么把表达式各项的系数拿出来相加就变成误差了？ 」
- - - - - - - - - - - - - - -
其实是惩罚，简单来说，正则化就是对越复杂的模型加大惩罚，因为越复杂的模型越容易过拟合。把惩罚加进误差里面，可以让我们选择一个误差较小的简单模型以避免过拟合@卓之

推荐一个概率统计的网站 可视化做得不错:
https://seeing-theory.brown.edu/cn.html#firstPage

## 12.29
「 远超-北京-互联网: #每日最少学习时间打卡#12.29
完成今日最少学习2小时
我学到了：感知器，是一种分类器，使用多元线性方程+阶跃函数进行运算，感知器的结果为1或者0。
问题：1）为什么课程中的感知器叫Logistic(对数概率)感知器，它和对数概率有什么关系？2）第7节习题2/4中，从AND感知器变成OR感知器，我举个例子AND感知器为w1=1,w2=1,b=-1.2，OR感知器为w1=1,w2=1,b=-0.5，这里的b由-1.2变为-0.5不是应该为“增大偏差大小”么？为什么正确答案是“减小偏差大小”？还是说偏差的大小只看b的绝对值？3）第9节的trainPerceptronAlgorithm函数中的x_min/x_max/y_min/y_max干啥用的？ 」
- - - - - - - - - - - - - - -
1. 观察很细致！这里应该是和对数概率没有关系的，实际上应该是逻辑运算符感知器，这里应该是出了翻译的错误，我会跟优达反映一下这个问题的！
2.看一下图中，是不是直线是往下移动了？往下移动了y=ax + b 是不是应该b减小了呀？
3.这个应该是没啥用，x_max是用来画图的时候初始化更加准确
@远超-北京-互联网

## 12.30
#每日最少学习时间打卡#12.30
完成今日最少学习4小时
我学到了：看西瓜书，复习模型评估与选择，加深理解并了解假设检验方法对模型进行比较检验。
